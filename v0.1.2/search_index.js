var documenterSearchIndex = {"docs":
[{"location":"","page":"Tutorial","title":"Tutorial","text":"(Image: CloudClusters.jl)","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"(Image: TagBot) (Image: CompatHelper)","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"A package for creating, using, and managing clusters of virtual machine (VM) instances deployed with IaaS cloud providers.","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"[!NOTE] Currently, only EC2 is supported. Those interested can ask us about progress with other providers. Contributors are welcome.","category":"page"},{"location":"#Target-users","page":"Tutorial","title":"Target users","text":"","category":"section"},{"location":"","page":"Tutorial","title":"Tutorial","text":"CloudClusters.jl targets Julia programming language users who need on-demand access to cutting-edge computing resources that IaaS cloud providers provide to meet high-performance computing (HPC) application requirements.","category":"page"},{"location":"#Pre-requisites","page":"Tutorial","title":"Pre-requisites","text":"","category":"section"},{"location":"#Cloud-providers'-credentials","page":"Tutorial","title":"Cloud providers' credentials","text":"","category":"section"},{"location":"","page":"Tutorial","title":"Tutorial","text":"Even though CloudClusters.jl currently only supports AWS EC2, it plans to support multiple IaaS cloud providers in the future. ","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"CloudClusters.jl assumes that the user has configured their credentials for the services of their preferred cloud providers in the environment.","category":"page"},{"location":"#The-configuration-file-(*CCconfig.toml*)","page":"Tutorial","title":"The configuration file (CCconfig.toml)","text":"","category":"section"},{"location":"","page":"Tutorial","title":"Tutorial","text":"Creating clusters with CloudClusters.jl requires specifying some configuration parameters. By default, they are specified in a file named CCconfig.toml that is searched in the following locations, in this order:","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"a path pointed by the CLOUDCLUSTERSCONFIG environment variable, if it exists;\nthe current path;\nthe home path.","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"Section Configuration parameters describes default configuration parameters and how they can be overridden in programs.  ","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"A CCconfig.toml file is provided in the repository's top-level directory. It is downloaded to the current directory if a CCconfig.toml file is not found. It is configured to create clusters using prebuilt virtual machine images for each supported cloud provider. These images are based on the latest version of Ubuntu and include a Julia installation of a recent stable version with all the packages needed to instantiate the clusters added and precompiled. Users can create customized images, possibly derived from the provided image, using their preferred version of Julia and adding the packages they need. ","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"[!WARNING] The version of Julia on the host computer using CloudClusters.jl must be the same version as the image used to deploy the clusters.","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"[!NOTE] The current prebuilt image for EC2 is located at the us-east-1 (North Virginia) region. Suppose the user is going to deploy a cluster in another region. In that case, they must create a copy of the image for that region in their account and assign their id to the imageid parameter of CCConfig.toml.","category":"page"},{"location":"#The-*PlatformAware.jl*-package","page":"Tutorial","title":"The PlatformAware.jl package","text":"","category":"section"},{"location":"","page":"Tutorial","title":"Tutorial","text":"CloudClusters.jl relies on an experimental package called PlatformAware.jl for the specification of platform types, aimed at specifying assumptions about architectural features of virtual machines instances. Indeed, PlatformAware.jl may be used with CloudClusters.jl to write functions specifically tuned according to the features of VM instances that comprise the clusters. This is called platform-aware programming. The users of CloudClusters.jl, particularly package developers, are invited to explore and use the ideas behind PlatformAware.jl.","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"Section The integration with PlatformAware.jl provides a deeper discussion about the integration of PlatformAware.jl within CloudClusters.jl.","category":"page"},{"location":"#Tutorial","page":"Tutorial","title":"Tutorial","text":"","category":"section"},{"location":"","page":"Tutorial","title":"Tutorial","text":"Next, we show a tutorial on how CloudClusters.jl works, divided into two parts: basic use and advanced use. ","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"The basic tutorial teaches the reader how to create and deploy computations on ___peer-workers___ clusters, comprising a set of homogeneous VM instances deployed in the infrastructure of an IaaS cloud provider. ","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"The advanced tutorial includes:","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"a deeper discussion about cluster contracts;\nhow to use MPI with ___peer-workers___ clusters;\nhow to create ___manager-workers___ clusters, a kind of cluster that comprises an access node and a set of homogenous compute nodes only accessible through the access node;\na description of configuration parameters and how programs can override the default values from the CCconfig.toml file.","category":"page"},{"location":"#Basic-use","page":"Tutorial","title":"Basic use","text":"","category":"section"},{"location":"","page":"Tutorial","title":"Tutorial","text":"In what follows, we teach how to create ___peer-workers___ clusters and deploy computations on them using Distributed.jl primitives.","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"Remember that the AWS credentials must be properly configured in the environment where the Julia REPL session or program will be executed. ","category":"page"},{"location":"#How-to-create-a-cluster","page":"Tutorial","title":"How to create a cluster","text":"","category":"section"},{"location":"","page":"Tutorial","title":"Tutorial","text":"CloudClusters.jl offers six primitives, as macros, to create and manage a cluster's lifecycle. They are: @cluster, @resolve, @deploy, @terminate, @interrupt, and @resume. ","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"First, let's try a simple scenario where a user creates a cluster comprising four ___t3.xlarge___ virtual machines (VM) instances through the AWS EC2 services. In the simplest way to do this, the user applies the @cluster macro to the number of nodes and instance type, as arguments. ","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"using CloudClusters\n\nmy_first_cluster_contract = @cluster  node_count => 4  node_machinetype => PlatformAware.EC2Type_T3_xLarge\n","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"EC2Type_T3_xLarge is a Julia type from the PlatformAware.jl package that represents the ___t3.xlarge___ instance type (and size) of EC2. PlatformAware.jl offers a hierarchy of types representing instance types of supported providers (e.g., MachineType → EC2Type → EC2Type_T3 → EC2Type_T3_xLarge).  For example, the user may list all the supported EC2 instance types by executing subtypes(PlatformAware.EC2Type) in the REPL, or subtypes(PlatformAware.EC2Type_T3) if the user intends to list the available instance sizes for the ___t3___ instance type.","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"@cluster does not instantiate a cluster yet. It creates a cluster contract and returns a handle for it. In the example, the contract handle is stored in the myfirstclustercontract_ variable, from which the user can create one or more clusters later. ","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"[!NOTE] In CloudClusters.jl, a handle is a symbol comprising 15 randomly calculated lower and upper case alphabetic characters (e.g.,:FXqElAnSeTEpQAm ). As symbols, they are printable and may be used directly to refer to a cluster contract.","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"A cluster contract must be resolved before creating clusters using it. For that, the user needs to apply @resolve to the contract handle, as below:","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"@resolve my_first_cluster_contract","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"The @resolve macro triggers a resolution procedure to calculate which instance type offered by one of the supported IaaS providers satisfies the contract. For my_first_cluster_contract, the result is explicitly specified: the ___t3.xlarge___ instance type of AWS EC2. For advanced contract specifications, where cluster contract resolution shows its power, the reader can read the Working with cluster contracts section.","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"A cluster may be instantiated by using ___@deploy___:","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"my_first_cluster = @deploy my_first_cluster_contract","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"The @deploy macro will create a 4-node cluster comprising ___t3.xlarge___ AWS EC2 instances, returning a cluster handle, assigned to the my_first_cluster variable. ","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"After @deploy, a set of worker processes is created, one at each cluster node. Their PIDs may be inspected by applying the ___nodes___ function to the cluster handle. ","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"In the following code, the user fetches the PIDs of the processes running at the nodes of the cluster referred to by my_first_cluster.","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"julia> @nodes my_first_cluster\n4-element Vector{Int64}\n2\n3\n4\n5","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"The example shows that the default number of worker processes per cluster node is 1. However, the user may create N worker processes per cluster node using the node_process_count => N parameter in the contract specification. For example, in the following contract, the number of worker processes per cluster node is set to 2:","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"@cluster  node_count => 4  node_process_count => 2  node_machinetype => EC2Type_T3_xLarge","category":"page"},{"location":"#Running-computations-on-the-cluster","page":"Tutorial","title":"Running computations on the cluster","text":"","category":"section"},{"location":"","page":"Tutorial","title":"Tutorial","text":"The user may execute parallel computations on the cluster using Distributed.jl operations. In fact, the user can employ any parallel/distributed computing package in the Julia ecosystem to launch computations across a set of worker processes. For instance, the advanced tutorial will show how to use MPI.jl integrated with Distributed.jl. ","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"The following code, adapted from The ultimate guide to distributed computing in Julia, processes a set of CSV files in a data folder in parallel, using pmap, across the worker processes placed at the cluster nodes. The result of each file processing is saved locally, as a CSV file in a results folder.  ","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"using Distributed\n\n@everywhere cluster_nodes(my_first_cluster) begin\n  # load dependencies\n  using ProgressMeter\n  using CSV\n\n  # helper functions\n  function process(infile, outfile)\n    # read file from disk\n    csv = CSV.File(infile)\n\n    # perform calculations\n    sleep(60)\n\n    # save new file to disk\n    CSV.write(outfile, csv)\n  end\nend\n\n# MAIN SCRIPT\n# -----------\n\n# relevant directories\nindir  = joinpath(@__DIR__,\"data\")\noutdir = joinpath(@__DIR__,\"results\")\n\n# files to process\ninfiles  = readdir(indir, join=true)\noutfiles = joinpath.(outdir, basename.(infiles))\nnfiles   = length(infiles)\n\nstatus = @showprogress pmap(1:nfiles; pids=cluster_nodes(my_first_cluster)) do i\n  try\n    process(infiles[i], outfiles[i])\n    true   # success\n  catch e\n    false  # failure\n  end\nend\n","category":"page"},{"location":"#Multiple-clusters","page":"Tutorial","title":"Multiple clusters","text":"","category":"section"},{"location":"","page":"Tutorial","title":"Tutorial","text":"Users can create cluster contracts and deploy clusters from them as many times as they need. For example, the following code creates a second cluster contract, named my_second_cluster_contract, asking for a cluster comprising eight VM instances equipped with exactly eight NVIDIA GPUs of Ada-Lovelace architecture and at least 512GB of memory per node. Then, it creates two clusters from the new contract. ","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"\nmy_second_cluster_contract = @cluster(node_count => 8,   \n                                      node_memory_size => @atleast(512G),\n                                      accelerator_count => @just(8),\n                                      accelerator_architecture => Ada)\n\n@resolve my_second_cluster_contract\n\nmy_second_cluster = @deploy my_second_cluster_contract\nmy_third_cluster = @deploy my_second_cluster_contract","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"This is an advanced use of cluster contracts, requiring instance types that satisfy a set of assumptions specified in the contract through instance parameters. This tutorial was written when the AWS EC2 instance type satisfying these assumptions is ___g6.48xlarge___, equipped with eight NVIDIA L4 T4 Tensor Core GPUs and 768GB of memory.","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"Now, there are three available clusters. The PIDs of the last two ones may also be inspected:","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"julia> @nodes my_second_cluster\n8-element Vector{Int64}\n6\n7\n8\n9\n10\n11\n12\n13\n\njulia> @ nodes my_third_cluster\n8-element Vector{Int64}\n14\n15\n16\n17\n18\n19\n20\n21","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"The user may orchestrate the processing power of multiple clusters to run computations of their interest, independent of their providers. This is multicluster computation. However, it is important to note that communication operations between processes placed at nodes of different clusters (inter-cluster communication), mainly when these clusters are deployed at different IaaS providers, must be used with care due to the high communication cost, only when necessary and overlapping communication and computation using asynchronous operations. ","category":"page"},{"location":"#Interrupting-and-resuming-a-cluster","page":"Tutorial","title":"Interrupting and resuming a cluster","text":"","category":"section"},{"location":"","page":"Tutorial","title":"Tutorial","text":"A cluster may be interrupted through the ___@interrupt___ macro: ","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"@interrupt my_first_cluster","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"The effect of ___@interrupt___ is pausing/stopping the VM instances of the cluster nodes. ","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"An interrupted cluster can be brought back to the running state using the ___@resume___ macro:","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"@resume my_first_cluster","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"The resuming operation starts the VM instances and creates a fresh set of worker processes, with new PIDs.","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"[!CAUTION] ___@interrupt___ does not preserve the state of undergoing computations in the cluster, since it kills the worker processes running at the cluster nodes. The interruption of a cluster may be used to avoid the cost of cloud resources that are not currently being used. The user is responsible for saving the state of undergoing computations in a cluster to be interrupted and reloading the state after resuming, if necessary. ","category":"page"},{"location":"#Restarting-processes","page":"Tutorial","title":"Restarting processes","text":"","category":"section"},{"location":"","page":"Tutorial","title":"Tutorial","text":"A user can restart the processes at the cluster nodes by using the ___@restart___ macro: ","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"@restart my_first_cluster","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"The restart procedure kills all the current processes at the cluster nodes, losing their current state, and creates new processes, with fresh PIDs. ","category":"page"},{"location":"#Terminating-a-cluster","page":"Tutorial","title":"Terminating a cluster","text":"","category":"section"},{"location":"","page":"Tutorial","title":"Tutorial","text":"Finally, a cluster may be finished/terminated using the ___@terminate___ macro:","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"@terminate my_first_cluster","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"After terminating, the cloud resources associated with the cluster are released.","category":"page"},{"location":"#How-to-reconnect-to-a-non-terminated-cluster","page":"Tutorial","title":"How to reconnect to a non-terminated cluster","text":"","category":"section"},{"location":"","page":"Tutorial","title":"Tutorial","text":"If a cluster was not terminated in a previous execution of a Julia program or REPL session, the user may reconnect it using the ___@reconnect___ macro. For example:","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"@reconnect :FXqElAnSeTEpQAm","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"In the above code, :FXqElAnSeTEpQAm is the handle of a cluster not terminated in a previous execution session. But how may the user discover the cluster handle of a non-terminated cluster? For example, after a system crash? For that, the user may call the ___@clusters___ macro, which returns a list of non-terminated clusters in previous sessions that are still alive and can be reconnected:","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"julia> @clusters\n[ Info: PeerWorkers FXqElAnSeTEpQAm, created at 2024-10-08T09:12:40.847 on PlatformAware.AmazonEC2\n1-element Vector{Any}:\n Dict{Any, Any}(:handle => :FXqElAnSeTEpQAm, :provider => PlatformAware.AmazonEC2, :type => PeerWorkers, :timestamp => Dates.DateTime(\"2024-10-08T09:12:40.847\"))","category":"page"},{"location":"#Advanced-Use","page":"Tutorial","title":"Advanced Use","text":"","category":"section"},{"location":"#Working-with-cluster-contracts","page":"Tutorial","title":"Working with cluster contracts","text":"","category":"section"},{"location":"","page":"Tutorial","title":"Tutorial","text":"As shown in the previous examples of using the ___@cluster___ macro, CloudClusters.jl supports cluster contracts to specify assumptions about cluster features, with special attention to the types of VM instances comprising cluster nodes. ","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"Cluster contracts are a set of key-value pairs k => v called assumption parameters, where k is a name and v is a value or platform type. A predefined set of assumption parameters is supported, each with a name and a default value or base platform type. ","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"The currently supported set of assumption parameters is listed here, providing a wide spectrum of assumptions for users to specify the architectural characteristics of a cluster to satisfy their needs. Note that assumption parameters are classified into cluster and instance parameters, where instance parameters are the assumption parameters considered in the instance resolution procedure (resolve).","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"In the case of my_first_cluster_contract, the user uses the assumption parameters ___nodecount___ and ___nodesmachinetype___ to specify that the required cluster must have four nodes and that the VM instances that comprise the cluster nodes must be of the ___t3.xlarge___ type, offered by the AWS EC2 provider. This is a direct approach, the simplest and least abstract one, where the resolution procedure, triggered by a call to @resolve, will return the EC2's ___t3.xlarge___ as the VM instance type that satisfies the contract.","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"On the other hand, my_second_cluster_contract employs an indirect approach, demonstrating that the resolution procedure may look for a VM instance type from a set of abstract assumptions. They are specified using the assumption parameters accelerator_count, accelerator_architecture, and accelerator_memory, asking for cluster nodes with eight GPUs of NVIDIA Ada Lovelace architecture and at least 512GB of memory. Under these assumptions, the call to ___@resolve___ returns the g6.48xlarge instance type of AWS EC2.","category":"page"},{"location":"#List-of-assumption-parameters","page":"Tutorial","title":"List of assumption parameters","text":"","category":"section"},{"location":"","page":"Tutorial","title":"Tutorial","text":"___Cluster parameters___ specify features of the cluster:","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"cluster_type::Cluster, denoting the cluster type: ManagerWorkers, PeerWorkers, or PeerWorkersMPI;\nnode_count::Integer, denoting the number of cluster nodes (default to 1);\nnodeprocesscount::Integer, denoting the number of Julia processes (MPI ranks) per node (default to 1).","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"___Instance parameters___, with their respective base platform types, are listed below:","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"node_provider::CloudProvider, the provider of VM instances for the cluster nodes;\ncluster_locale::Locale, the geographic location where the cluster nodes will be instantiated;\nnode_machinetype::InstanceType, the VM instance type of cluster nodes;\nnodememorysize::@atleast 0, the memory size of each cluster node;\nnodeecucount::@atleast 1, the EC2 compute unit, a processing performance measure for VM instances (only for EC2 instances);\nnodevcpusunit::@atleast 1, the number of virtual CPUs in each cluster node;\naccelerator_count::@atleast 0, the number of accelerators in the cluster node;\naccelerator_memory::@atleast 0, the amount of memory of the cluster node accelerators;\naccelerator_type::AcceleratorType, the type of accelerator;\naccelerator_manufacturer::AcceleratorManufacturer, the manufacturer of the accelerator;\naccelerator_arch::AcceleratorArchitecture, the architecture of the accelerator, depending on its type and manufacturer.\naccelerator::AcceleratorModel, the accelerator model;\nprocessor_manufacturer::Manufacturer, the processor manufacturer;\nprocessor_microarchitecture::ProcessorArchitecture, the processor microarchitecture;\nprocessor::ProcessorModel, the processor model;\nstorage_type::StorageType, the type of storage in cluster nodes;\nstorage_size::@atleast 0, the size of the storage in cluster nodes;\nnetwork_performance::@atleast 0, the network performance between cluster nodes.","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"Most platform types are specified in the PlatformAware.jl package. The user may open a REPL section to query types defined in PlatformAware.jl. For example, the user may apply the subtypes function to know the subtypes of a given platform type, which define the available choices:","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"\njulia> using PlatformAware\n\njulia> subtypes(Accelerator)\n3-element Vector{Any}:\n NVIDIAAccelerator\n AMDAccelerator\n IntelAccelerator\n\njulia> subtypes(EC2Type_T3)\n8-element Vector{Any}:\n EC2Type_T3A\n EC2Type_T3_2xLarge\n EC2Type_T3_Large\n EC2Type_T3_Medium\n EC2Type_T3_Micro\n EC2Type_T3_Nano\n EC2Type_T3_Small\n EC2Type_T3_xLarge","category":"page"},{"location":"#Querying-contracts","page":"Tutorial","title":"Querying contracts","text":"","category":"section"},{"location":"","page":"Tutorial","title":"Tutorial","text":"In the current implementation of CloudClusters.jl, since contract resolution, using ___@resolve___, is implemented on top of Julia's multiple dispatch mechanism, it does not support ambiguity, i.e., only a single VM instance type must satisfy the contract. Otherwise, ___resolve___ returns an ambiguity error, like in the example below:","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"julia> cc = @cluster(node_count => 4, \n                     accelerator_count => @atleast(4),\n                     accelerator_architecture => Ada, \n                     node_memory_size => @atleast(256G))\n:NKPlCvagfSSpIgD\n\njulia> @resolve cc\nERROR: MethodError: resolve(::Type{CloudProvider}, ::Type{MachineType}, ::Type{Tuple{AtLeast256G, AtMostInf, var\"#92#X\"} where var\"#92#X\"}, ::Type{Tuple{AtLeast1, AtMostInf, Q} where Q}, ::Type{Tuple{AtLeast4, AtMostInf, var\"#91#X\"} where var\"#91#X\"}, ::Type{AcceleratorType}, ::Type{Ada}, ::Type{Manufacturer}, ::Type{Tuple{AtLeast0, AtMostInf, Q} where Q}, ::Type{Accelerator}, ::Type{Processor}, ::Type{Manufacturer}, ::Type{ProcessorMicroarchitecture}, ::Type{StorageType}, ::Type{Tuple{AtLeast0, AtMostInf, Q} where Q}, ::Type{Tuple{AtLeast0, AtMostInf, Q} where Q}) is ambiguous.","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"The user can use the ___@select___ macro to query which instance types satisfy the ambiguous contract: ","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"julia> @select(node_count => 4,\n               accelerator_count => @atleast(4),\n               accelerator_architecture => Ada, \n               node_memory_size => @atleast(256G))\n┌ Warning: Only instance features are allowed. Ignoring node_count.\n└ @ CloudClusters ~/Dropbox/Copy/ufc_mdcc_hpc/CloudClusters.jl/src/resolve.jl:78\nDict{String, Any} with 3 entries:\n  \"g6.48xlarge\"    => Dict{Symbol, Any}(:processor => Type{>:AMDEPYC_7R13}, :accelerator_architecture => Type{>:Ada}, :processor_manufacturer => Type{>:AMD}, :storage_type => Type{>:StorageType_EC2_NVMeSSD}, :node_memory_size => Type{>:Tuple{AtLeast512G, AtMost1T, 8.24634e11}}, :storage_size => Type{>:Tuple{AtLeast32T, AtMost64T, 6.52835e13}}, :node_provider => Type{>:AmazonEC2}, :node_vcpus_count => Type{>:Tuple{AtLeast128, AtMost256, 192.0}}, :accelerator_count => Type{>:Tuple{AtLeast8, AtMost8, 8.0}}, :network_performance => Type{>:Tuple{AtLeast64G, AtMost128G, 1.07374e11}}, :accelerator => Type{>:NVIDIA_L4}, :accelerator_type => Type{>:GPU}, :accelerator_memory_size => Type{>:Tuple{AtLeast16G, AtMost32G, 2.57698e10}}, :accelerator_manufacturer => Type{>:NVIDIA}, :node_machinetype => Type{>:EC2Type_G6_48xLarge}, :processor_microarchitecture => Type{>:Zen})\n  \"g2-standard-96\" => Dict{Symbol, Any}(:processor => Type{>:IntelXeon_8280L}, :accelerator_architecture => Type{>:Ada}, :processor_manufacturer => Type{>:Intel}, :storage_type => Type{>:StorageType}, :node_memory_size => Type{>:Tuple{AtLeast256G, AtMost512G, 4.12317e11}}, :storage_size => Type{>:Tuple{AtLeast0, AtMostInf, Q} where Q}, :node_provider => Type{>:GoogleCloud}, :node_vcpus_count => Type{>:Tuple{AtLeast64, AtMost128, 96.0}}, :accelerator_count => Type{>:Tuple{AtLeast8, AtMost8, 8.0}}, :network_performance => Type{>:Tuple{AtLeast64G, AtMost128G, 1.07374e11}}, :accelerator => Type{>:NVIDIA_L4}, :accelerator_type => Type{>:GPU}, :accelerator_memory_size => Type{>:Tuple{AtLeast16G, AtMost32G, 2.57698e10}}, :accelerator_manufacturer => Type{>:NVIDIA}, :node_machinetype => Type{>:GCPType_G2}, :processor_microarchitecture => Type{>:CascadeLake})\n  \"g6.24xlarge\"    => Dict{Symbol, Any}(:processor => Type{>:AMDEPYC_7R13}, :accelerator_architecture => Type{>:Ada}, :processor_manufacturer => Type{>:AMD}, :storage_type => Type{>:StorageType_EC2_NVMeSSD}, :node_memory_size => Type{>:Tuple{AtLeast256G, AtMost512G, 4.12317e11}}, :storage_size => Type{>:Tuple{AtLeast8T, AtMost16T, 1.63209e13}}, :node_provider => Type{>:AmazonEC2}, :node_vcpus_count => Type{>:Tuple{AtLeast64, AtMost128, 96.0}}, :accelerator_count => Type{>:Tuple{AtLeast4, AtMost4, 4.0}}, :network_performance => Type{>:Tuple{AtLeast32G, AtMost64G, 5.36871e10}}, :accelerator => Type{>:NVIDIA_L4}, :accelerator_type => Type{>:GPU}, :accelerator_memory_size => Type{>:Tuple{AtLeast16G, AtMost32G, 2.57698e10}}, :accelerator_manufacturer => Type{>:NVIDIA}, :node_machinetype => Type{>:EC2Type_G6_24xLarge}, :processor_microarchitecture => Type{>:Zen})","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"Notice that ___@select___ emits a warning because node_count is ignored since only instance features are considered in contract resolution.","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"Three VM instance types satisfy the contract, since they provide at least 256GB of memory and at least four NVIDIA GPUs of Ada architecture (L4 Tensor Core). They are: ___g6.48xlarge___, ___g2-standard-96___, and ___g6.24xlarge___. The user may inspect the features of each instance type and write a contract that selects one directly.","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"julia> cc = @cluster  node_count => 4  node_machinetype => EC2Type_G6_48xLarge\n:mBrvXUsilkpxWJC\n\njulia> @resolve cc\n1-element Vector{Pair{Symbol, SubString{String}}}:\n :instance_type => \"g6.48xlarge\"","category":"page"},{"location":"#Peer-Workers-MPI-clusters","page":"Tutorial","title":"Peer-Workers-MPI clusters","text":"","category":"section"},{"location":"","page":"Tutorial","title":"Tutorial","text":"___Peer-Workers-MPI___ is a variation of ___Peer-Workers___ clusters, where worker processes are connected through a global MPI communicator. This is possible through MPI.jl and MPIClusterManagers.jl. ","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"In what follows, we modify the my_second_cluster_contract to build a ___Peer-Workers-MPI___ cluster that will be referred by my_fourth_cluster``´, by using thecluster_type``` parameter:","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"my_third_cluster_contract = @cluster(cluster_type => PeerWorkersMPI,\n                                     node_count => 8,   \n                                     node_memory_size => @atleast(512G),\n                                     accelerator_count => @just(8),\n                                     accelerator_architecture => Ada)\nmy_fourth_cluster = @deploy my_third_cluster_contract","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"The following code launches a simple MPI.jl code in myfourthcluster, using the @everywhere primitive of Distributed.jl. ","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"\n@everywhere cluster_nodes(my_fourth_cluster) begin\n   @eval using MPI\n   MPI.Init()\n   rank = MPI.Comm_rank(MPI.COMM_WORLD)\n   size = MPI.Comm_size(MPI.COMM_WORLD)\n   @info \"I am $rank among $size processes\"\n   root_rank = 0\n   rank_sum = MPI.Reduce(rank, (x,y) -> x + y, root_rank, MPI.COMM_WORLD)\nend\n\nresult = @fetchfrom ranks(my_first_cluster)[0] rank_sum\n@info \"The sum of ranks in the cluster is $result\"","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"The parallel code sums the ranks of the processes using the Reduce collective operation of MPI.jl and stores the result in the global variable ranksum_ of the root process (rank 0). Then, this value is fetched by the program and assigned to the result variable using @fetchfrom. For that, the ranks function is used to discover the PID of the root process. ","category":"page"},{"location":"#Manager-Workers-clusters","page":"Tutorial","title":"Manager-Workers clusters","text":"","category":"section"},{"location":"","page":"Tutorial","title":"Tutorial","text":"A ___Manager-Workers___ cluster comprises an access node and a homogenous set of compute nodes. The compute nodes are only accessible from the access node. The instance type of the access node may be different from the instance type of the compute nodes. ","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"In a ___Manager-Workers___ cluster, the master process, running in the REPL or main program, is called the driver process. It is responsible for launching the so-called entry process in the cluster's access node. In turn, the entry process launches worker processes across the compute nodes, using MPIClusterManagers.jl. The worker processes perform the computation, while the entry process is responsible for communication between the driver and the worker processes. A global MPI communicator exists between worker processes, like in ___Peer-Workers-MPI___ clusters.","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"A ___Manager-Workers___ cluster is useful when compute nodes are not directly accessible from the external network. This is a common situation in on-premises clusters. However, this is also possible in clusters built from the services of cluster providers  specifically tailored to HPC applications.","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"[!IMPORTANT] ___Manager-Workers___ are not natively supported by Julia, because Distributed.jl does not support that worker processes create new processes, as shown below:julia>addprocs(1)\n1-element Vector{Int64}:\n2\njulia> @fetchfrom 2 addprocs(1)\nERROR: On worker 2:\nOnly process 1 can add or remove workersThe CloudClusters.jl developers have developed an extended version of Distributed.jl that removes this limitation, making it possible to create hierarchies of Julia processes [2]. However, the multilevel extension of Distributed.jl is necessary only for the access node of ___Manager-Workers___ cluster, where the so-called entry processes, launched by the master process at the REPL/program and responsible for launching the worker processes across computing nodes of the cluster, will be running. So, only users who need to develop customized images to instantiate cluster nodes must be concerned with adapting the Julia installation for the extended Distributed.jl version, and only if an image is intended to be used for manager nodes of ___Manager-Workers___ clusters.The multilevel extension to Distributed.jl is hosted at https://github.com/PlatformAwareProgramming/Distributed.jl, as a fork of the original Distributed.jl repository. The README of Distributed.jl explains how to use development versions in a current Julia installation. In case of difficulties, the user may contact the developers of CloudClusters.jl. For more information about the multilevel extension of Distributed.jl, read the SSCAD'2024 paper Towards multicluster computations with Julia.","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"Users may apply the cluster_type parameter to command the creation of a ___Manager-Workers___ cluster. Let us modify the my_first_cluster_contract to create a ___Manager-Workers___ cluster instead of a ___Peer-Workers___ one (default):","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"my_first_cluster_contract = @cluster(cluster_type => ManageWorkers,\n                                     node_count => 4,\n                                     node_machinetype => EC2Type_T3_xLarge)       ","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"In this case, the node_count parameter specifies the number of worker nodes. So, for a cluster deployed using my_first_cluster_contract, five VM instances will be created, including the manager node.","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"The user may use \"dot notation\" to specify different assumptions for manager and worker nodes. For example:","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"my_second_cluster_contract = @cluster(cluster_type => ManageWorkers,\n                                      node_count => 8,\n                                      manager.node_machinetype => EC2Type_T3_xLarge,\n                                      worker.accelerator_count => @just(8),\n                                      worker.accelerator_architecture => Ada,   \n                                      worker.accelerator_memory => @atleast(512G))","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"This contract specifies that the manager node must be a ___t3.xlarge___ VM instance, while the worker nodes will have eight NVIDIA GPUs of Ada architecture and at least 512GB of memory.","category":"page"},{"location":"#Configuration-parameters","page":"Tutorial","title":"Configuration parameters","text":"","category":"section"},{"location":"","page":"Tutorial","title":"Tutorial","text":"Configuration parameters exist for the proper instantiation of clusters, whose default values are specified in the CCconfig.toml file. The user may override the default values by passing configuration parameters through ___@cluster___ and ___@deploy___ operations. For instance:","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"my_cluster_contract = @cluster(node_count => 4,\n                               node_machinetype => EC2Type_T3_xLarge,\n                               image_id => \"ami-07f6c5b6de73ce7ae\")\n\nmy_cluster = @deploy(my_first_cluster,\n                     user => \"ubuntu\",\n                     sshflags => \"-i mykey.pem\")","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"In the above code, image_id specifies that the EC2 image identified by ami-07f6c5b6de73ce7ae must be used when creating clusters from myclustercontract. On the other hand, user and sshflags will be used to access the nodes of mycluster_. For instance, ami-07f6c5b6de73ce7ae may provide a set of predefined users with different privileges to access the features offered by such an image.","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"Currently, there are four categories of configuration parameters. They are described in the following paragraphs.","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"The following configuration parameters set up the SSH connections to nodes of ___Peer-Workers___ clusters and the manager node of ___Master-Worker___ clusters, i.e., those nodes that are externally accessible:","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"user::String, the user login to access VM instances (e.g., user@xxx.xxx.xxx.xxx, where xxx.xxx.xxx.xxx is the public IP of the VM instance);\nsshflags::String, the flags that must be passed to the ssh command to access the VM instances;\ntunneled::Bool, a keyword argument to be passed to addprocs to determine whether or not ssh access should be tunneled.","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"The following configuration parameters apply to cluster nodes of any cluster type:","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"exename::String, the full path to the julia executable (e.g., /home/ubuntu/.juliaup/bin/julia);\nexeflags::String, flags to be passed to the julia executable when starting processes on cluster nodes;\ndirectory::String, the current directory of the julia execution in the VM instance.","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"The following configuration parameters apply to nodes of ___Peer-Workers-MPI___ and worker nodes of ___Manager-Workers___ clusters, i.e., the ones with MPI-based message-passing enabled:","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"threadlevel::Symbol, a keyword argument passed to MPI.Init, whose possible values are: single, :serialized, :funneled, :multiple; \nmpiflags::String, a keyword argument passed to MPI (e.g., \"--map-by node --hostfile /home/ubuntu/hostfile\"). ","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"The last set of configuration parameters depends on the IaaS provider selected through @resolve. For AWS EC2, they are:","category":"page"},{"location":"","page":"Tutorial","title":"Tutorial","text":"imageid::String, the ID of the image used to instantiate the VM instances that form the cluster nodes;\nsubnet_id::String, the ID of a subnet for the communication between VM instances that form the cluster nodes;\nplacement_group::String, the ID of an existing placement group where the user wishes to colocate the VM instances that form the cluster nodes (the default is to create a temporary placement group);\nsecuritygroupid::String, the ID of an existing security group for the VM instances that form the cluster nodes.","category":"page"},{"location":"#The-integration-with-PlatformAware.jl","page":"Tutorial","title":"The integration with PlatformAware.jl","text":"","category":"section"},{"location":"","page":"Tutorial","title":"Tutorial","text":"UNDER CONSTRUCTION","category":"page"},{"location":"#Publications","page":"Tutorial","title":"Publications","text":"","category":"section"},{"location":"","page":"Tutorial","title":"Tutorial","text":"Francisco Heron de Carvalho Junior, João Marcelo Uchoa de Alencar, and Claro Henrique Silva Sales. 2024. ___Cloud-based parallel computing across multiple clusters in Julia___. In Proceedings of the 28th Brazilian Symposium on Programming Languages (SBLP'2024), September 30, 2024, Curitiba, Brazil. SBC, Porto Alegre, Brasil, 44-52. DOI: https://doi.org/10.5753/sblp.2024.3470.\nFrancisco Heron de Carvalho Junior and Tiago Carneiro. 2024. ___Towards multicluster computations with Julia___. In Proceedings of the XXV Symposium on High-Performance Computational Systems (SSCAD’2024), October 25, 2024, São Carlos, Brazil. SBC, Porto Alegre, Brazil. DOI: https://doi.org/10.5753/sscad.2024.244307","category":"page"}]
}
