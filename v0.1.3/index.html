<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Tutorial · CloudClusters.jl</title><meta name="title" content="Tutorial · CloudClusters.jl"/><meta property="og:title" content="Tutorial · CloudClusters.jl"/><meta property="twitter:title" content="Tutorial · CloudClusters.jl"/><meta name="description" content="Documentation for CloudClusters.jl."/><meta property="og:description" content="Documentation for CloudClusters.jl."/><meta property="twitter:description" content="Documentation for CloudClusters.jl."/><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="search_index.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>CloudClusters.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Tutorial</a><ul class="internal"><li><a class="tocitem" href="#Target-users"><span>Target users</span></a></li><li><a class="tocitem" href="#Pre-requisites"><span>Pre-requisites</span></a></li><li class="toplevel"><a class="tocitem" href="#Tutorial"><span>Tutorial</span></a></li><li class="toplevel"><a class="tocitem" href="#Basic-use"><span>Basic use</span></a></li><li><a class="tocitem" href="#How-to-create-a-cluster"><span>How to create a cluster</span></a></li><li><a class="tocitem" href="#Running-computations-on-the-cluster"><span>Running computations on the cluster</span></a></li><li><a class="tocitem" href="#Multiple-clusters"><span>Multiple clusters</span></a></li><li><a class="tocitem" href="#Interrupting-and-resuming-a-cluster"><span>Interrupting and resuming a cluster</span></a></li><li><a class="tocitem" href="#Restarting-processes"><span>Restarting processes</span></a></li><li><a class="tocitem" href="#Terminating-a-cluster"><span>Terminating a cluster</span></a></li><li><a class="tocitem" href="#How-to-reconnect-to-a-non-terminated-cluster"><span>How to reconnect to a non-terminated cluster</span></a></li><li><a class="tocitem" href="#Advanced-Use"><span>Advanced Use</span></a></li><li class="toplevel"><a class="tocitem" href="#Publications"><span>Publications</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Tutorial</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Tutorial</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/PlatformAwareProgramming/CloudClusters.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/PlatformAwareProgramming/CloudClusters.jl/blob/main/docs/src/index.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><p><img src="https://raw.githubusercontent.com/PlatformAwareProgramming/CloudClusters.jl/refs/heads/main/docs/src/assets/logo-text.svg" alt="CloudClusters.jl"/></p><p><a href="https://github.com/PlatformAwareProgramming/CloudClusters.jl/actions/workflows/TagBot.yml"><img src="https://github.com/PlatformAwareProgramming/CloudClusters.jl/actions/workflows/TagBot.yml/badge.svg" alt="TagBot"/></a></p><p><a href="https://github.com/PlatformAwareProgramming/CloudClusters.jl/actions/workflows/CompatHelper.yml"><img src="https://github.com/PlatformAwareProgramming/CloudClusters.jl/actions/workflows/CompatHelper.yml/badge.svg" alt="CompatHelper"/></a></p><p><em>A package for creating, using, and managing clusters of virtual machine (VM) instances deployed with IaaS cloud providers.</em></p><h2 id="Target-users"><a class="docs-heading-anchor" href="#Target-users">Target users</a><a id="Target-users-1"></a><a class="docs-heading-anchor-permalink" href="#Target-users" title="Permalink"></a></h2><p><em>CloudClusters.jl</em> targets Julia programming language users who need on-demand access to cutting-edge computing resources that IaaS cloud providers provide to meet high-performance computing (HPC) application requirements.</p><h2 id="Pre-requisites"><a class="docs-heading-anchor" href="#Pre-requisites">Pre-requisites</a><a id="Pre-requisites-1"></a><a class="docs-heading-anchor-permalink" href="#Pre-requisites" title="Permalink"></a></h2><h3 id="Cloud-providers&#39;-credentials"><a class="docs-heading-anchor" href="#Cloud-providers&#39;-credentials">Cloud providers&#39; credentials</a><a id="Cloud-providers&#39;-credentials-1"></a><a class="docs-heading-anchor-permalink" href="#Cloud-providers&#39;-credentials" title="Permalink"></a></h3><p>Currently, <em>CloudClusters.jl</em> supports AWS EC2 and Google Cloud Platform (GCP). In future versions, the support to other IaaS cloud providers may be implemented.</p><p><em>CloudClusters.jl</em> assumes that the user has configured the system with the required credentials for the cloud providers&#39; services they will use.  For GCP, <em>CloudClusters.jl</em> starts a session using the <a href="https://cloud.google.com/docs/authentication/application-default-credentials">JSON credential file</a> informed through the GOOGLE<em>APPLICATION</em>CREDENTIALS environment variable. In turn, the EC2 API will look for <a href="https://docs.aws.amazon.com/cli/v1/userguide/cli-configure-files.html#cli-configure-files-where">credential files</a> in the HOME/.aws folder. </p><h3 id="The-configuration-file-(*CCconfig.toml*)"><a class="docs-heading-anchor" href="#The-configuration-file-(*CCconfig.toml*)">The configuration file (<em>CCconfig.toml</em>)</a><a id="The-configuration-file-(*CCconfig.toml*)-1"></a><a class="docs-heading-anchor-permalink" href="#The-configuration-file-(*CCconfig.toml*)" title="Permalink"></a></h3><p>Creating clusters with <em>CloudClusters.jl</em> requires specifying some configuration parameters. By default, they are specified in a file named <em>CCconfig.toml</em> that is searched in the following locations, in this order:</p><ul><li>a path pointed by the CLOUD<em>CLUSTERS</em>CONFIG environment variable, if it exists;</li><li>the current path;</li><li>the home path.</li></ul><p>Section <a href="https://github.com/PlatformAwareProgramming/CloudClusters.jl#configuration-parameters">Configuration parameters</a> describes default configuration parameters and how they can be overridden in programs.</p><p>A <a href="https://raw.githubusercontent.com/PlatformAwareProgramming/CloudClusters.jl/refs/heads/main/CCconfig.toml"><em>CCconfig.toml</em></a> file is provided in the repository&#39;s top-level directory. It is downloaded to the current directory if a <em>CCconfig.toml</em> file is not found. It is configured to create clusters using prebuilt virtual machine images for each supported cloud provider. These images are based on the latest version of Ubuntu and include a Julia installation of a recent stable version with all the packages needed to instantiate the clusters added and precompiled. Users can create customized images, possibly derived from the provided image, using their preferred version of Julia and adding the packages they need.</p><blockquote><p>[!WARNING] The version of Julia on the host computer using <em>CloudClusters.jl</em> must be the same version as the image used to deploy the clusters. [!NOTE] The current prebuilt image for EC2 is located at the <em>us-east-1</em> (North Virginia) region. Suppose the user is going to deploy a cluster in another region. In that case, they must create a copy of the image for that region in their account and assign their id to the <code>imageid</code> parameter of <em>CCConfig.toml</em>.</p></blockquote><h3 id="The-*PlatformAware.jl*-package"><a class="docs-heading-anchor" href="#The-*PlatformAware.jl*-package">The <em>PlatformAware.jl</em> package</a><a id="The-*PlatformAware.jl*-package-1"></a><a class="docs-heading-anchor-permalink" href="#The-*PlatformAware.jl*-package" title="Permalink"></a></h3><p><em>CloudClusters.jl</em> relies on an experimental package called <a href="https://github.com/PlatformAwareProgramming/PlatformAware.jl"><em>PlatformAware.jl</em></a> for the specification of <em>platform types</em>, aimed at specifying assumptions about architectural features of virtual machines instances. Indeed, <em>PlatformAware.jl</em> may be used with <em>CloudClusters.jl</em> to write functions specifically tuned according to the features of VM instances that comprise the clusters. This is called <em>[platform-aware programming</em>](https://sol.sbc.org.br/index.php/sscad/article/view/26529). The users of <em>CloudClusters.jl</em>, particularly package developers, are invited to explore and use the ideas behind <em>PlatformAware.jl</em>.</p><p>Section <a href="https://github.com/PlatformAwareProgramming/CloudClusters.jl#the-integration-with-platformawarejl">The integration with PlatformAware.jl</a> provides a deeper discussion about the integration of <em>PlatformAware.jl</em> within <em>CloudClusters.jl</em>.</p><h1 id="Tutorial"><a class="docs-heading-anchor" href="#Tutorial">Tutorial</a><a id="Tutorial-1"></a><a class="docs-heading-anchor-permalink" href="#Tutorial" title="Permalink"></a></h1><p>Next, we show a tutorial on how <em>CloudClusters.jl</em> works, divided into two parts: <em>basic use</em> and <em>advanced use</em>.</p><p>The basic tutorial teaches the reader how to create and deploy computations on ___peer-workers___ clusters, comprising a set of homogeneous VM instances deployed in the infrastructure of an IaaS cloud provider.</p><p>The advanced tutorial includes:</p><ul><li><p><a href="https://github.com/PlatformAwareProgramming/CloudClusters.jl#working-with-cluster-contracts">a deeper discussion about <em>cluster contracts</em></a>;</p></li><li><p><a href="https://github.com/PlatformAwareProgramming/CloudClusters.jl#peer-workers-mpi-clusters">how to use MPI with ___peer-workers___ clusters</a>;</p></li><li><p><a href="https://github.com/PlatformAwareProgramming/CloudClusters.jl#manager-workers-clusters">how to create ___manager-workers___ clusters, a kind of cluster that comprises an access node and a set of homogenous compute nodes only accessible through the access node</a>;</p></li><li><p><a href="https://github.com/PlatformAwareProgramming/CloudClusters.jl#configuration-parameters">a description of configuration parameters and how programs can override the default values from the <em>CCconfig.toml</em> file</a>.</p></li></ul><h1 id="Basic-use"><a class="docs-heading-anchor" href="#Basic-use">Basic use</a><a id="Basic-use-1"></a><a class="docs-heading-anchor-permalink" href="#Basic-use" title="Permalink"></a></h1><p>In what follows, we teach how to create ___peer-workers___ clusters and deploy computations on them using <em>Distributed.jl</em> primitives.  </p><h2 id="How-to-create-a-cluster"><a class="docs-heading-anchor" href="#How-to-create-a-cluster">How to create a cluster</a><a id="How-to-create-a-cluster-1"></a><a class="docs-heading-anchor-permalink" href="#How-to-create-a-cluster" title="Permalink"></a></h2><p><em>CloudClusters.jl</em> offers seven primitives, as <em>macros</em>, to create and manage a cluster&#39;s lifecycle. They are: <strong>@cluster</strong>, <strong>@resolve</strong>, <strong>@deploy</strong>, <strong>@terminate</strong>, <strong>@interrupt</strong>,  <strong>@resume</strong>, and <strong>@restart</strong>.</p><p>First, let&#39;s try a simple scenario where a user creates a cluster comprising four ___t3.xlarge___ virtual machines (VM) instances through the AWS EC2 services. In the simplest way to do this, the user applies the <strong>@cluster</strong> macro to the number of nodes and instance type, as arguments.</p><pre><code class="language-julia hljs">using CloudClusters
my_first_contract = @cluster node_count =&gt; 4 node_machinetype =&gt; PlatformAware.EC2Type_T3_xLarge</code></pre><p><code>EC2Type_T3_xLarge</code> is a Julia type from the <em>PlatformAware.jl</em> package that represents the ___t3.xlarge___ instance type (and size) of EC2. <em>PlatformAware.jl</em> offers a hierarchy of types representing instance types of supported providers (e.g., <code>MachineType</code> → <code>EC2Type</code> → <code>EC2Type_T3</code> → <code>EC2Type_T3_xLarge</code> and <code>MachineType</code> → <code>GCPType</code> → <code>GCPType_E2</code> → <code>GCPType_E2_Medium</code>).</p><p>The user may list all the supported EC2 instance types by executing <code>subtypes(PlatformAware.EC2Type)</code> in the REPL, or <code>subtypes(PlatformAware.EC2Type_T3)</code> if the user intends to list the available instance sizes for the ___t3___ instance type. Analougously for GCP.</p><p><strong>@cluster</strong> does not instantiate a cluster yet. It creates a <em>cluster contract</em> and returns a handle for it. In the example, the <em>contract handle</em> is stored in the <em>my</em>first<em>cluster</em>contract_ variable, from which the user can create one or more clusters later.</p><blockquote><p>[!NOTE]</p></blockquote><blockquote><p>In <em>CloudClusters.jl</em>, a handle is a symbol comprising 15 random lower and upper case alphabetic characters (e.g.,<code>:FXqElAnSeTEpQAm</code> ). As symbols, they are printable and may be used directly to refer to a cluster contract.</p></blockquote><p>A cluster contract must be resolved before creating clusters using it. For that, the user needs to apply <strong>@resolve</strong> to the contract handle, as below:</p><pre><code class="language-julia hljs">@resolve my_first_contract</code></pre><p>The <strong>@resolve</strong> macro triggers a resolution procedure to calculate which instance type offered by one of the supported IaaS providers satisfies the contract. For <code>my_first_contract</code>, the result is explicitly specified: the ___t3.xlarge___ instance type of AWS EC2. For advanced contract specifications, where cluster contract resolution shows its power, the reader can read the <a href="https://github.com/PlatformAwareProgramming/CloudClusters.jl#working-with-cluster-contracts">Working with cluster contracts</a> section.</p><p>A cluster may be instantiated by using ___@deploy___:</p><pre><code class="language-julia hljs">my_first_cluster = @deploy my_first_cluster_contract</code></pre><p>The <strong>@deploy</strong> macro will create a 4-node cluster comprising ___t3.xlarge___ AWS EC2 instances, returning a cluster handle, assigned to the <code>my_first_cluster</code> variable.</p><p>After <strong>@deploy</strong>, a set of <em>worker processes</em> is created, one at each cluster node. Their <em>PIDs</em> may be inspected by applying the ___nodes___ function to the cluster handle.</p><p>In the following code, the user uses <strong>@nodes</strong> to fetch the <em>PIDs</em> of the processes running at the nodes of the cluster referred to by <code>my_first_cluster</code>.</p><pre><code class="language-julia-repl hljs">julia&gt; @nodes my_first_cluster
4-element Vector{Int64}
2
3
4
5</code></pre><p>The example shows that the default number of worker processes per cluster node is 1. However, the user may create N worker processes per cluster node using the <code>node_process_count =&gt; N</code> parameter in the contract specification. For example, in the following contract, the number of worker processes per cluster node is set to 2:</p><pre><code class="language-julia hljs">@cluster node_count =&gt; 4 node_process_count =&gt; 2 node_machinetype =&gt; EC2Type_T3_xLarge</code></pre><h2 id="Running-computations-on-the-cluster"><a class="docs-heading-anchor" href="#Running-computations-on-the-cluster">Running computations on the cluster</a><a id="Running-computations-on-the-cluster-1"></a><a class="docs-heading-anchor-permalink" href="#Running-computations-on-the-cluster" title="Permalink"></a></h2><p>The user may execute parallel computations on the cluster using <em>Distributed.jl</em> operations. In fact, the user can employ any parallel/distributed computing package in the Julia ecosystem to launch computations across a set of worker processes. For instance, the advanced tutorial will show how to use <em>MPI.jl</em> integrated with <em>Distributed.jl</em>.</p><p>The following code, adapted from <a href="https://github.com/Arpeggeo/julia-distributed-computing#the-ultimate-guide-to-distributed-computing-in-julia">The ultimate guide to distributed computing in Julia</a>, processes a set of CSV files in a data folder in parallel, using <em>pmap</em>, across the worker processes placed at the cluster nodes. The result of each file processing is saved locally, as a CSV file in a results folder.</p><pre><code class="language-julia hljs">using Distributed

@everywhere cluster_nodes(my_first_cluster) begin

	# load dependencies
	using ProgressMeter
	using CSV

	# helper functions
	function  process(infile, outfile)
		# read file from disk
		csv = CSV.File(infile)

		# perform calculations
		sleep(60)

		# save new file to disk
		CSV.write(outfile, csv)
	end
end

# MAIN SCRIPT
# -----------

# relevant directories
indir = joinpath(@__DIR__,&quot;data&quot;)
outdir = joinpath(@__DIR__,&quot;results&quot;)

# files to process
infiles = readdir(indir, join=true)
outfiles = joinpath.(outdir, basename.(infiles))
nfiles = length(infiles)

status = @showprogress  pmap(1:nfiles; pids=cluster_nodes(my_first_cluster)) do i
	try
		process(infiles[i], outfiles[i])
		true  # success
	catch e
		false  # failure
	end
end</code></pre><h2 id="Multiple-clusters"><a class="docs-heading-anchor" href="#Multiple-clusters">Multiple clusters</a><a id="Multiple-clusters-1"></a><a class="docs-heading-anchor-permalink" href="#Multiple-clusters" title="Permalink"></a></h2><p>Users can create cluster contracts and deploy clusters from them as many times as they need. For example, the following code creates a second cluster contract, named <code>my_second_cluster_contract</code>, asking for a cluster comprising eight VM instances equipped with exactly eight NVIDIA GPUs of Ada-Lovelace architecture and at least 512GB of memory per node. Then, it creates two clusters from the new contract.</p><pre><code class="language-julia hljs">my_second_contract = @cluster(node_count =&gt; 8,
                              node_memory_size =&gt; @atleast(512G),
                              accelerator_count =&gt; @just(8),
                              accelerator_architecture =&gt; Ada)

@resolve my_second_cluster_contract

my_second_cluster = @deploy my_second_cluster_contract
my_third_cluster = @deploy my_second_cluster_contract</code></pre><p>This is an advanced use of cluster contracts, requiring instance types that satisfy a set of assumptions specified in the contract through instance parameters. This tutorial was written when the AWS EC2 instance type satisfying these assumptions is ___g6.48xlarge___, equipped with eight NVIDIA L4 T4 Tensor Core GPUs and 768GB of memory.</p><p>Now, there are three available clusters. The <em>PIDs</em> of the last two ones may also be inspected:</p><pre><code class="language-julia-repl hljs">julia&gt; @nodes my_second_cluster
8-element Vector{Int64}
6
7
8
9
10
11
12
13

julia&gt; @ nodes my_third_cluster
8-element Vector{Int64}
14
15
16
17
18
19
20
21</code></pre><p>The user may orchestrate the processing power of multiple clusters to run computations of their interest, independent of their providers. This is <em>multicluster computation</em>. However, it is important to note that communication operations between processes placed at nodes of different clusters (inter-cluster communication), mainly when these clusters are deployed at different IaaS providers, must be used with care due to the high communication cost, only when necessary and overlapping communication and computation using asynchronous operations.</p><h2 id="Interrupting-and-resuming-a-cluster"><a class="docs-heading-anchor" href="#Interrupting-and-resuming-a-cluster">Interrupting and resuming a cluster</a><a id="Interrupting-and-resuming-a-cluster-1"></a><a class="docs-heading-anchor-permalink" href="#Interrupting-and-resuming-a-cluster" title="Permalink"></a></h2><p>A cluster may be interrupted through the ___@interrupt___ macro:</p><pre><code class="language-julia hljs">@interrupt my_first_cluster</code></pre><p>The effect of ___@interrupt___ is pausing/stopping the VM instances of the cluster nodes. The semantics of interrupting a cluster may vary accross IaaS providers.</p><p>An interrupted cluster can be brought back to the running state using the ___@resume___ macro:</p><pre><code class="language-julia hljs">@resume my_first_cluster</code></pre><p>The resume operation starts the VM instances and creates a fresh set of worker processes, with new <em>PIDs</em>.</p><blockquote><p>[!CAUTION]</p></blockquote><blockquote><p>___@interrupt___ does not preserve the state of undergoing computations in the cluster, since it kills the worker processes running at the cluster nodes. The interruption of a cluster may be used to avoid the cost of cloud resources that are not currently being used. The user is responsible for saving the state of undergoing computations in a cluster to be interrupted and reloading the state after resuming, if necessary.</p></blockquote><h2 id="Restarting-processes"><a class="docs-heading-anchor" href="#Restarting-processes">Restarting processes</a><a id="Restarting-processes-1"></a><a class="docs-heading-anchor-permalink" href="#Restarting-processes" title="Permalink"></a></h2><p>A user can restart the processes at the cluster nodes by using the ___@restart___ macro:</p><pre><code class="language-julia hljs">@restart my_first_cluster</code></pre><p>The restart procedure kills all the current processes at the cluster nodes, losing their current state, and creates new processes, with fresh <em>PIDs</em>.</p><h2 id="Terminating-a-cluster"><a class="docs-heading-anchor" href="#Terminating-a-cluster">Terminating a cluster</a><a id="Terminating-a-cluster-1"></a><a class="docs-heading-anchor-permalink" href="#Terminating-a-cluster" title="Permalink"></a></h2><p>Finally, a cluster may be finished/terminated using the ___@terminate___ macro:</p><pre><code class="language-julia hljs">@terminate my_first_cluster</code></pre><p>After terminating, the cloud resources associated with the cluster are released.</p><h2 id="How-to-reconnect-to-a-non-terminated-cluster"><a class="docs-heading-anchor" href="#How-to-reconnect-to-a-non-terminated-cluster">How to reconnect to a non-terminated cluster</a><a id="How-to-reconnect-to-a-non-terminated-cluster-1"></a><a class="docs-heading-anchor-permalink" href="#How-to-reconnect-to-a-non-terminated-cluster" title="Permalink"></a></h2><p>If a cluster was not terminated in a previous execution of a Julia program or REPL session, the user may reconnect it using the ___@reconnect___ macro. For example:</p><pre><code class="language-julia hljs">@reconnect :FXqElAnSeTEpQAm</code></pre><p>In the above code, <code>:FXqElAnSeTEpQAm</code> is the handle of a cluster not terminated in a previous execution session. But how may the user discover the cluster handle of a non-terminated cluster? For example, after a system crash? For that, the user may invoke the ___@clusters___ macro, which returns a list of non-terminated clusters in previous sessions that are still alive and can be reconnected:</p><pre><code class="language-julia hljs">julia&gt; @clusters
[ Info: PeerWorkers FXqElAnSeTEpQAm, created at 2024-10-08T09:12:40.847 on PlatformAware.AmazonEC2
1-element Vector{Any}:
Dict{Any, Any}(:handle =&gt; :FXqElAnSeTEpQAm, :provider =&gt; PlatformAware.AmazonEC2, :type =&gt; PeerWorkers, :timestamp =&gt; Dates.DateTime(&quot;2024-10-08T09:12:40.847&quot;))</code></pre><h2 id="Advanced-Use"><a class="docs-heading-anchor" href="#Advanced-Use">Advanced Use</a><a id="Advanced-Use-1"></a><a class="docs-heading-anchor-permalink" href="#Advanced-Use" title="Permalink"></a></h2><h3 id="Working-with-cluster-contracts"><a class="docs-heading-anchor" href="#Working-with-cluster-contracts">Working with cluster contracts</a><a id="Working-with-cluster-contracts-1"></a><a class="docs-heading-anchor-permalink" href="#Working-with-cluster-contracts" title="Permalink"></a></h3><p>As shown in the previous examples of using the ___@cluster___ macro, <em>CloudClusters.jl</em> supports <em>cluster contracts</em> to specify <em>assumptions</em> about cluster <em>features</em>, with special attention to the types of VM instances comprising cluster nodes.</p><p>Cluster contracts are a set of key-value pairs <code>k =&gt; v</code> called <em>assumption parameters</em>, where <code>k</code> is a name and <code>v</code> is a value or <a href><em>platform type</em></a>. A predefined set of assumption parameters is supported, each with a <em>name</em> and a default value or <em>base platform type</em>.</p><p>The currently supported set of assumption parameters is listed <a href="https://github.com/PlatformAwareProgramming/CloudClusters.jl#configuration-parameters">here</a>, providing a wide spectrum of assumptions for users to specify the architectural characteristics of a cluster to satisfy their needs. Note that assumption parameters are classified into cluster and instance parameters, where <em>instance parameters</em> are taken into consideration in the instance resolution procedure (<strong>@resolve</strong>).</p><p>In the case of <code>my_first_contract</code>, the user uses the assumption parameters ___node<em>count___ and ___nodes</em>machinetype___ to specify that the required cluster must have four nodes and that the VM instances that comprise the cluster nodes must be of the ___t3.xlarge___ type, offered by the AWS EC2 provider. This is a direct approach, the simplest and least abstract one, where the resolution procedure, triggered by a call to <strong>@resolve</strong>, will return the EC2&#39;s ___t3.xlarge___ as the VM instance type that satisfies the contract.</p><p>On the other hand, <code>my_second_contract</code> employs an indirect approach, demonstrating that the resolution procedure may look for a VM instance type from a set of abstract assumptions. They are specified using the instance parameters <strong>accelerator_count</strong>, <strong>accelerator_architecture</strong>, and <strong>accelerator_memory</strong>, asking for cluster nodes with eight GPUs of NVIDIA Ada Lovelace architecture and at least 512GB of memory. Under these assumptions, the call to ___@resolve___ returns the <strong>g6.48xlarge</strong> instance type of AWS EC2.</p><h4 id="List-of-assumption-parameters"><a class="docs-heading-anchor" href="#List-of-assumption-parameters">List of assumption parameters</a><a id="List-of-assumption-parameters-1"></a><a class="docs-heading-anchor-permalink" href="#List-of-assumption-parameters" title="Permalink"></a></h4><p>___Cluster parameters___ specify features of the cluster:</p><ul><li><strong>cluster_type</strong>::<code>Cluster</code>, denoting the cluster type: ManagerWorkers, PeerWorkers, or PeerWorkersMPI;</li><li><strong>node_count</strong>::<code>Integer</code>, denoting the number of cluster nodes (default to <em>1</em>);</li><li><strong>node<em>process</em>count</strong>::<code>Integer</code>, denoting the number of Julia processes (MPI ranks) per node (default to <em>1</em>).</li></ul><p>___Instance parameters___, with their respective base platform types, are listed below:</p><ul><li><strong>node_provider</strong>::<code>CloudProvider</code>, the provider of VM instances for the cluster nodes;</li><li><strong>cluster_locale</strong>::<code>Locale</code>, the geographic location where the cluster nodes will be instantiated;</li><li><strong>node_machinetype</strong>::<code>InstanceType</code>, the VM instance type of cluster nodes;</li><li><strong>node<em>memory</em>size</strong>::<code>@atleast 0</code>, the memory size of each cluster node;</li><li><strong>node<em>ecu</em>count</strong>::<code>@atleast 1</code>, the EC2 compute unit, a processing performance measure for VM instances (only for EC2 instances);</li><li><strong>node<em>vcpus</em>unit</strong>::<code>@atleast 1</code>, the number of virtual CPUs in each cluster node;</li><li><strong>accelerator_count</strong>::<code>@atleast 0</code>, the number of accelerators in the cluster node;</li><li><strong>accelerator_memory</strong>::<code>@atleast 0</code>, the amount of memory of the cluster node accelerators;</li><li><strong>accelerator_type</strong>::<code>AcceleratorType</code>, the type of accelerator;</li><li><strong>accelerator_manufacturer</strong>::<code>AcceleratorManufacturer</code>, the manufacturer of the accelerator;</li><li><strong>accelerator_arch</strong>::<code>AcceleratorArchitecture</code>, the architecture of the accelerator, depending on its type and manufacturer.</li><li><strong>accelerator</strong>::<code>AcceleratorModel</code>, the accelerator model;</li><li><strong>processor_manufacturer</strong>::<code>Manufacturer</code>, the processor manufacturer;</li><li><strong>processor_microarchitecture</strong>::<code>ProcessorArchitecture</code>, the processor microarchitecture;</li><li><strong>processor</strong>::<code>ProcessorModel</code>, the processor model;</li><li><strong>storage_type</strong>::<code>StorageType</code>, the type of storage in cluster nodes;</li><li><strong>storage_size</strong>::<code>@atleast 0</code>, the size of the storage in cluster nodes;</li><li><strong>network_performance</strong>::<code>@atleast 0</code>, the network performance between cluster nodes.</li></ul><p>Most platform types are specified in the <em>PlatformAware.jl</em> package. The user may open a REPL section to query types defined in <em>PlatformAware.jl</em>. For example, the user may apply the <a href="https://www.jlhub.com/julia/manual/en/function/subtypes"><code>subtypes</code> function</a> to know the subtypes of a given platform type, which define the available choices:</p><pre><code class="language-julia-repl hljs">julia&gt; using PlatformAware

julia&gt; subtypes(Accelerator)
3-element Vector{Any}:
NVIDIAAccelerator
AMDAccelerator
IntelAccelerator

julia&gt; subtypes(EC2Type_T3)
8-element Vector{Any}:
EC2Type_T3A
EC2Type_T3_2xLarge
EC2Type_T3_Large
EC2Type_T3_Medium
EC2Type_T3_Micro
EC2Type_T3_Nano
EC2Type_T3_Small
EC2Type_T3_xLarge</code></pre><h4 id="Querying-contracts"><a class="docs-heading-anchor" href="#Querying-contracts">Querying contracts</a><a id="Querying-contracts-1"></a><a class="docs-heading-anchor-permalink" href="#Querying-contracts" title="Permalink"></a></h4><p>In the current implementation of <em>CloudClusters.jl</em>, since contract resolution, using ___@resolve___, is implemented on top of Julia&#39;s multiple dispatch mechanism, it does not support ambiguity, i.e., only a single VM instance type must satisfy the contract. Otherwise, ___resolve___ returns an ambiguity error, like in the example below:</p><pre><code class="language-julia-repl hljs">julia&gt; cc = @cluster(node_count =&gt; 4,
                     accelerator_count =&gt; @atleast(4),
                     accelerator_architecture =&gt; Ada,
                     node_memory_size =&gt; @atleast(256G))
:NKPlCvagfSSpIgD

julia&gt; @resolve cc
ERROR: MethodError: resolve(::Type{CloudProvider}, ::Type{MachineType}, ::Type{Tuple{AtLeast256G, AtMostInf, var&quot;#92#X&quot;} where var&quot;#92#X&quot;}, ::Type{Tuple{AtLeast1, AtMostInf, Q} where Q}, ::Type{Tuple{AtLeast4, AtMostInf, var&quot;#91#X&quot;} where var&quot;#91#X&quot;}, ::Type{AcceleratorType}, ::Type{Ada}, ::Type{Manufacturer}, ::Type{Tuple{AtLeast0, AtMostInf, Q} where Q}, ::Type{Accelerator}, ::Type{Processor}, ::Type{Manufacturer}, ::Type{ProcessorMicroarchitecture}, ::Type{StorageType}, ::Type{Tuple{AtLeast0, AtMostInf, Q} where Q}, ::Type{Tuple{AtLeast0, AtMostInf, Q} where Q}) is ambiguous.</code></pre><p>The user can use the ___@select___ macro to query which instance types satisfy the ambiguous contract:</p><pre><code class="language-julia-repl hljs">julia&gt; @select(node_count =&gt; 4,
               accelerator_count =&gt; @atleast(4),
               accelerator_architecture =&gt; Ada,
               node_memory_size =&gt; @atleast(256G))
┌ Warning: Only instance features are allowed. Ignoring node_count.
└ @ CloudClusters ~/Dropbox/Copy/ufc_mdcc_hpc/CloudClusters.jl/src/resolve.jl:78
Dict{String, Any} with 3 entries:
&quot;g6.48xlarge&quot; =&gt; Dict{Symbol, Any}(:processor =&gt; Type{&gt;:AMDEPYC_7R13}, :accelerator_architecture =&gt; Type{&gt;:Ada}, :processor_manufacturer =&gt; Type{&gt;:AMD}, :storage_type =&gt; Type{&gt;:StorageType_EC2_NVMeSSD}, :node_memory_size =&gt; Type{&gt;:Tuple{AtLeast512G, AtMost1T, 8.24634e11}}, :storage_size =&gt; Type{&gt;:Tuple{AtLeast32T, AtMost64T, 6.52835e13}}, :node_provider =&gt; Type{&gt;:AmazonEC2}, :node_vcpus_count =&gt; Type{&gt;:Tuple{AtLeast128, AtMost256, 192.0}}, :accelerator_count =&gt; Type{&gt;:Tuple{AtLeast8, AtMost8, 8.0}}, :network_performance =&gt; Type{&gt;:Tuple{AtLeast64G, AtMost128G, 1.07374e11}}, :accelerator =&gt; Type{&gt;:NVIDIA_L4}, :accelerator_type =&gt; Type{&gt;:GPU}, :accelerator_memory_size =&gt; Type{&gt;:Tuple{AtLeast16G, AtMost32G, 2.57698e10}}, :accelerator_manufacturer =&gt; Type{&gt;:NVIDIA}, :node_machinetype =&gt; Type{&gt;:EC2Type_G6_48xLarge}, :processor_microarchitecture =&gt; Type{&gt;:Zen})
&quot;g2-standard-96&quot; =&gt; Dict{Symbol, Any}(:processor =&gt; Type{&gt;:IntelXeon_8280L}, :accelerator_architecture =&gt; Type{&gt;:Ada}, :processor_manufacturer =&gt; Type{&gt;:Intel}, :storage_type =&gt; Type{&gt;:StorageType}, :node_memory_size =&gt; Type{&gt;:Tuple{AtLeast256G, AtMost512G, 4.12317e11}}, :storage_size =&gt; Type{&gt;:Tuple{AtLeast0, AtMostInf, Q} where Q}, :node_provider =&gt; Type{&gt;:GoogleCloud}, :node_vcpus_count =&gt; Type{&gt;:Tuple{AtLeast64, AtMost128, 96.0}}, :accelerator_count =&gt; Type{&gt;:Tuple{AtLeast8, AtMost8, 8.0}}, :network_performance =&gt; Type{&gt;:Tuple{AtLeast64G, AtMost128G, 1.07374e11}}, :accelerator =&gt; Type{&gt;:NVIDIA_L4}, :accelerator_type =&gt; Type{&gt;:GPU}, :accelerator_memory_size =&gt; Type{&gt;:Tuple{AtLeast16G, AtMost32G, 2.57698e10}}, :accelerator_manufacturer =&gt; Type{&gt;:NVIDIA}, :node_machinetype =&gt; Type{&gt;:GCPType_G2}, :processor_microarchitecture =&gt; Type{&gt;:CascadeLake})
&quot;g6.24xlarge&quot; =&gt; Dict{Symbol, Any}(:processor =&gt; Type{&gt;:AMDEPYC_7R13}, :accelerator_architecture =&gt; Type{&gt;:Ada}, :processor_manufacturer =&gt; Type{&gt;:AMD}, :storage_type =&gt; Type{&gt;:StorageType_EC2_NVMeSSD}, :node_memory_size =&gt; Type{&gt;:Tuple{AtLeast256G, AtMost512G, 4.12317e11}}, :storage_size =&gt; Type{&gt;:Tuple{AtLeast8T, AtMost16T, 1.63209e13}}, :node_provider =&gt; Type{&gt;:AmazonEC2}, :node_vcpus_count =&gt; Type{&gt;:Tuple{AtLeast64, AtMost128, 96.0}}, :accelerator_count =&gt; Type{&gt;:Tuple{AtLeast4, AtMost4, 4.0}}, :network_performance =&gt; Type{&gt;:Tuple{AtLeast32G, AtMost64G, 5.36871e10}}, :accelerator =&gt; Type{&gt;:NVIDIA_L4}, :accelerator_type =&gt; Type{&gt;:GPU}, :accelerator_memory_size =&gt; Type{&gt;:Tuple{AtLeast16G, AtMost32G, 2.57698e10}}, :accelerator_manufacturer =&gt; Type{&gt;:NVIDIA}, :node_machinetype =&gt; Type{&gt;:EC2Type_G6_24xLarge}, :processor_microarchitecture =&gt; Type{&gt;:Zen})</code></pre><p>Notice that ___@select___ emits a warning because <strong>node_count</strong> is ignored since only instance features are considered in contract resolution.</p><p>Three VM instance types satisfy the contract, since they provide at least 256GB of memory and at least four NVIDIA GPUs of Ada architecture (L4 Tensor Core). They are: ___g6.48xlarge___, ___g2-standard-96___, and ___g6.24xlarge___. The user may inspect the features of each instance type and write a contract that selects one directly.</p><pre><code class="language-julia-repl hljs">julia&gt; cc = @cluster node_count =&gt; 4 node_machinetype =&gt; EC2Type_G6_48xLarge
:mBrvXUsilkpxWJC

julia&gt; @resolve cc
1-element Vector{Pair{Symbol, SubString{String}}}:
:instance_type =&gt; &quot;g6.48xlarge&quot;</code></pre><h3 id="Peer-Workers-MPI-clusters"><a class="docs-heading-anchor" href="#Peer-Workers-MPI-clusters">Peer-Workers-MPI clusters</a><a id="Peer-Workers-MPI-clusters-1"></a><a class="docs-heading-anchor-permalink" href="#Peer-Workers-MPI-clusters" title="Permalink"></a></h3><p>___Peer-Workers-MPI___ is a variation of ___Peer-Workers___ clusters, where worker processes are connected through a global MPI communicator. This is possible through <em>MPI.jl</em> and <em>MPIClusterManagers.jl</em>.</p><p>In what follows, we modify the <code>my_second_contract</code> to build a ___Peer-Workers-MPI___ cluster that will be referred by <code>my_fourth_cluster</code>, by using the <code>cluster_type</code> parameter:</p><pre><code class="language-julia hljs">my_third__contract = @cluster(cluster_type =&gt; PeerWorkersMPI,
                              node_count =&gt; 8,
                              node_memory_size =&gt; @atleast(512G),
                              accelerator_count =&gt; @just(8),
                              accelerator_architecture =&gt; Ada)

my_fourth_cluster = @deploy my_third_cluster_contract</code></pre><p>The following code launches a simple <em>MPI.jl</em> code in <em>my</em>fourth<em>cluster</em>, using the <code>@everywhere</code> primitive of <em>Distributed.jl</em>.</p><pre><code class="language-julia hljs">@everywhere  cluster_nodes(my_fourth_cluster) begin
	@eval  using MPI
	MPI.Init()
	rank = MPI.Comm_rank(MPI.COMM_WORLD)
	size = MPI.Comm_size(MPI.COMM_WORLD)
	@info  &quot;I am $rank among $size processes&quot;
	root_rank = 0
	rank_sum = MPI.Reduce(rank, (x,y) -&gt; x + y, root_rank, MPI.COMM_WORLD)
end

result = @fetchfrom  ranks(my_first_cluster)[0] rank_sum
@info  &quot;The sum of ranks in the cluster is $result&quot;</code></pre><p>The parallel code sums the ranks of the processes using the <em>Reduce</em> collective operation of <em>MPI.jl</em> and stores the result in the global variable <em>rank</em>sum_ of the root process (rank 0). Then, this value is fetched by the program and assigned to the result variable using <code>@fetchfrom</code>. For that, the <code>ranks</code> function is used to discover the <em>PID</em> of the root process.</p><h3 id="Manager-Workers-clusters"><a class="docs-heading-anchor" href="#Manager-Workers-clusters">Manager-Workers clusters</a><a id="Manager-Workers-clusters-1"></a><a class="docs-heading-anchor-permalink" href="#Manager-Workers-clusters" title="Permalink"></a></h3><p>A ___Manager-Workers___ cluster comprises an <em>access node</em> and a homogenous set of <em>compute nodes</em>. The compute nodes are only accessible from the access node. The instance type of the access node may be different from the instance type of the compute nodes.</p><p>In a ___Manager-Workers___ cluster, the master process, running in the REPL or main program, is called the <em>driver process</em>. It is responsible for launching the so-called <em>entry process</em> in the cluster&#39;s access node. In turn, the entry process launches <em>worker processes</em> across the compute nodes, using <em>MPIClusterManagers.jl</em>. The worker processes perform the computation, while the entry process is responsible for communication between the driver and the worker processes. A global MPI communicator exists between worker processes, like in ___Peer-Workers-MPI___ clusters.</p><p>A ___Manager-Workers___ cluster is useful when compute nodes are not directly accessible from the external network. This is a common situation in on-premises clusters. However, this is also possible in clusters built from the services of cluster providers specifically tailored to HPC applications.</p><blockquote><p>[!IMPORTANT]</p></blockquote><blockquote><p>___Manager-Workers___ are not natively supported by Julia, because <em>Distributed.jl</em> does not support that worker processes create new processes, as shown below:</p></blockquote><blockquote><pre><code class="language-julia-repl hljs"> julia&gt;addprocs(1)
 1-element Vector{Int64}:
 
 julia&gt; @fetchfrom  2  addprocs(1)
 ERROR: On worker 2:
 Only process 1 can add or remove workers</code></pre></blockquote><blockquote><p>The <em>CloudClusters.jl</em> developers have developed an extended version of <em>Distributed.jl</em> that removes this limitation, making it possible to create hierarchies of Julia processes [2]. However, the multilevel extension of <em>Distributed.jl</em> is necessary only for the access node of ___Manager-Workers___ cluster, where the so-called <em>entry processes</em>, launched by the master process at the REPL/program and responsible for launching the worker processes across computing nodes of the cluster, will be running.</p><p>So, only users who need to develop customized images to instantiate cluster nodes must be concerned with adapting the Julia installation for the extended <em>Distributed.jl</em> version, and only if an image is intended to be used for manager nodes of ___Manager-Workers___ clusters.</p><p>The multilevel extension to <em>Distributed.jl</em> is hosted at https://github.com/PlatformAwareProgramming/Distributed.jl, as a fork of <a href="https://github.com/JuliaLang/Distributed.jl">the original <em>Distributed.jl</em> repository</a>. The README of <em>Distributed.jl</em> explains <a href="https://github.com/JuliaLang/Distributed.jl#using-development-versions-of-this-package">how to use development versions in a current Julia installation</a>. In case of difficulties, the user may contact the developers of <em>CloudClusters.jl</em>. For more information about the multilevel extension of <em>Distributed.jl</em>, read the SSCAD&#39;2024 paper <a href="https://sol.sbc.org.br/index.php/sscad/article/view/31004">Towards multicluster computations with Julia</a>.</p></blockquote><p>Users may apply the <strong>cluster_type</strong> parameter to command the creation of a ___Manager-Workers___ cluster. Let us modify the <code>my_first_cluster_contract</code> to create a ___Manager-Workers___ cluster instead of a ___Peer-Workers___ one (default):</p><pre><code class="language-julia hljs">my_first_cluster_contract = @cluster(cluster_type =&gt; ManageWorkers,
node_count =&gt; 4,
node_machinetype =&gt; EC2Type_T3_xLarge)</code></pre><p>In this case, the <strong>node_count</strong> parameter specifies the number of worker nodes. So, for a cluster deployed using <code>my_first_cluster_contract</code>, five VM instances will be created, including the manager node.</p><p>The user may use &quot;dot notation&quot; to specify different assumptions for manager and worker nodes. For example:</p><pre><code class="language-julia hljs">my_second_contract = @cluster(cluster_type =&gt; ManageWorkers,
                              node_count =&gt; 8,
                              manager.node_machinetype =&gt; EC2Type_T3_xLarge,
                              worker.accelerator_count =&gt; @just(8),
                              worker.accelerator_architecture =&gt; Ada,
                              worker.accelerator_memory =&gt; @atleast(512G))</code></pre><p>This contract specifies that the manager node must be a ___t3.xlarge___ VM instance, while the worker nodes will have eight NVIDIA GPUs of Ada architecture and at least 512GB of memory.</p><h3 id="Configuration-parameters"><a class="docs-heading-anchor" href="#Configuration-parameters">Configuration parameters</a><a id="Configuration-parameters-1"></a><a class="docs-heading-anchor-permalink" href="#Configuration-parameters" title="Permalink"></a></h3><p>Configuration parameters exist for the proper instantiation of clusters, whose default values are specified in the <em>CCconfig.toml</em> file. The user may override the default values by passing configuration parameters through ___@cluster___ and ___@deploy___ operations. For instance:</p><pre><code class="language-julia hljs">my_cluster_contract = @cluster(node_count =&gt; 4,
                               node_machinetype =&gt; EC2Type_T3_xLarge,
                               image_id =&gt; &quot;ami-07f6c5b6de73ce7ae&quot;)
                               my_cluster = @deploy(my_first_cluster,
                               user =&gt; &quot;ubuntu&quot;,
                               sshflags =&gt; &quot;-i mykey.pem&quot;)</code></pre><p>In the above code, <code>image_id</code> specifies that the EC2 image identified by <code>ami-07f6c5b6de73ce7ae</code> must be used when creating clusters from <em>my</em>cluster<em>contract</em>. On the other hand, <code>user</code> and <code>sshflags</code> will be used to access the nodes of <em>my</em>cluster_. For instance, <code>ami-07f6c5b6de73ce7ae</code> may provide a set of predefined users with different privileges to access the features offered by such an image.</p><p>Currently, there are four categories of configuration parameters. They are described in the following paragraphs.</p><p>The following configuration parameters set up the SSH connections to nodes of ___Peer-Workers___ clusters and the manager node of ___Master-Worker___ clusters, i.e., those nodes that are externally accessible:</p><ul><li><strong>user</strong>::<code>String</code>, the user login to access VM instances (e.g., <code>user@xxx.xxx.xxx.xxx</code>, where <code>xxx.xxx.xxx.xxx</code> is the public IP of the VM instance);</li><li><strong>sshflags</strong>::<code>String</code>, the flags that must be passed to the ssh command to access the VM instances;</li><li><strong>tunneled</strong>::<code>Bool</code>, a keyword argument to be passed to <code>addprocs</code> to determine whether or not ssh access should be <a href="https://www.ssh.com/academy/ssh/tunneling">tunneled</a>.</li></ul><p>The following configuration parameters apply to cluster nodes of any cluster type:</p><ul><li><strong>exename</strong>::<code>String</code>, the full path to the <code>julia</code> executable (e.g., /home/ubuntu/.juliaup/bin/julia);</li><li><strong>exeflags</strong>::<code>String</code>, flags to be passed to the <code>julia</code> executable when starting processes on cluster nodes;</li><li><strong>directory</strong>::<code>String</code>, the current directory of the <code>julia</code> execution in the VM instance.</li></ul><p>The following configuration parameters apply to nodes of ___Peer-Workers-MPI___ and worker nodes of ___Manager-Workers___ clusters, i.e., the ones with MPI-based message-passing enabled:</p><ul><li><strong>threadlevel</strong>::<code>Symbol</code>, a keyword argument passed to <code>MPI.Init</code>, whose possible values are: <a href="https://juliaparallel.org/MPI.jl/stable/reference/environment/#MPI.ThreadLevel"><code>single</code>, <code>:serialized</code>, <code>:funneled</code>, <code>:multiple</code></a>;</li><li><strong>mpiflags</strong>::<code>String</code>, a keyword argument passed to MPI (e.g., <code>&quot;--map-by node --hostfile /home/ubuntu/hostfile&quot;</code>).</li></ul><p>The last set of configuration parameters depends on the IaaS provider selected through <strong>@resolve</strong>. </p><p>For AWS EC2, they are:</p><ul><li><strong>imageid</strong>::<code>String</code>, the <em>ID</em> of the image used to instantiate the VM instances that form the cluster nodes;</li><li><strong>subnet_id</strong>::<code>String</code>, the <em>ID</em> of a subnet for the communication between VM instances that form the cluster nodes;</li><li><strong>placement_group</strong>::<code>String</code>, the <em>ID</em> of an existing placement group where the user wishes to colocate the VM instances that form the cluster nodes (the default is to create a temporary placement group);</li><li><strong>security<em>group</em>id</strong>::<code>String</code>, the <em>ID</em> of an existing security group for the VM instances that form the cluster nodes.</li></ul><p>Finally, for GCP, they are:</p><ul><li><strong>imageid</strong>::<code>String</code>, the <em>ID</em> of the image used to instantiate the VM instances that form the cluster nodes;</li><li><strong>zone</strong>::<code>String</code>, the <a href="https://cloud.google.com/compute/docs/regions-zones">zone</a> where the cluster node instances will be placed;</li><li><strong>project</strong>::<code>String</code>, the <a href="https://cloud.google.com/storage/docs/projects">project</a> where the cluster node instances will be created;</li><li><strong>network_interface</strong>::<code>String</code>, the <em>network interface</em> of cluster node instances.</li></ul><h3 id="The-integration-with-PlatformAware.jl"><a class="docs-heading-anchor" href="#The-integration-with-PlatformAware.jl">The integration with PlatformAware.jl</a><a id="The-integration-with-PlatformAware.jl-1"></a><a class="docs-heading-anchor-permalink" href="#The-integration-with-PlatformAware.jl" title="Permalink"></a></h3><p>UNDER CONSTRUCTION</p><h1 id="Publications"><a class="docs-heading-anchor" href="#Publications">Publications</a><a id="Publications-1"></a><a class="docs-heading-anchor-permalink" href="#Publications" title="Permalink"></a></h1><ul><li><p>Francisco Heron de Carvalho Junior, João Marcelo Uchoa de Alencar, and Claro Henrique Silva Sales. 2024. ___Cloud-based parallel computing across multiple clusters in Julia___. In Proceedings of the <em>28th Brazilian Symposium on Programming Languages</em> (SBLP&#39;2024), September 30, 2024, Curitiba, Brazil. SBC, Porto Alegre, Brasil, 44-52. DOI: https://doi.org/10.5753/sblp.2024.3470.</p></li><li><p>Francisco Heron de Carvalho Junior and Tiago Carneiro. 2024. ___Towards multicluster computations with Julia___. In Proceedings of the XXV Symposium on High-Performance Computational Systems (SSCAD’2024), October 25, 2024, São Carlos, Brazil. SBC, Porto Alegre, Brazil. DOI: https://doi.org/10.5753/sscad.2024.244307</p></li></ul></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.0 on <span class="colophon-date" title="Thursday 6 February 2025 14:25">Thursday 6 February 2025</span>. Using Julia version 1.11.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
